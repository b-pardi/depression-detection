{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c436e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome\n"
     ]
    }
   ],
   "source": [
    "# Dependencies are in requirments.txt\n",
    "# list dependencies for this specific part\n",
    "# imports!!\n",
    "'''\n",
    "transformers torch langchain sentence transformers pinecone\n",
    "'''\n",
    "\n",
    "print(\"Welcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8b73c",
   "metadata": {},
   "source": [
    "## Document Process Splitting \n",
    "\n",
    "split by diagnostic section or pages (see if it can handle entire sections)\n",
    "\n",
    "top-K: try out 5-10\n",
    "\n",
    "### Input: PDF documents (see Clinical_data) Output: set of chunks of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e6553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "649c9175",
   "metadata": {},
   "source": [
    "## Generate Embeddings \n",
    "convert chunks into vector embeddings\n",
    "\n",
    "### Input: set of chunks of text  Output: set of vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b84221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca51f047",
   "metadata": {},
   "source": [
    "## Set up vector Database\n",
    "name: clinical-RAG\n",
    "pinecone\n",
    "### Input: set of vector embeddings Output: Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07c06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30eab497",
   "metadata": {},
   "source": [
    "## Load llama 3B model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef165f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama model to add to\n",
    "\n",
    "# test model works as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7b3d2",
   "metadata": {},
   "source": [
    "## Build Retrieval Pipeline\n",
    "create a function that takes the user's query, converts it to an embedding and retrieves the top-k most relevant document chunks from clinical-rag database\n",
    "\n",
    "### input: user query (diac-woz convo) output: top-k relevant clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb270b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "436b9ade",
   "metadata": {},
   "source": [
    "## Generation pipeline\n",
    "build the prompt that combines the retreived context with the diac woz convo  to fill out the form: read this convo: convo.... and this criteria: top-k criteria.... and return this sheet: possible symptoms:(...) and depression symptom severity(choose one: none, moderete, severe)\n",
    "\n",
    "\n",
    "### Input: top-k relevant clinical data + Diac-woz conversation Output: prompt for RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed77613",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "convo = convo\n",
    "top_k = (list of top k criteria)\n",
    "\n",
    "prompt = read this conversation: {convo} and this criteria: {top_k} and return this sheet: possible symptoms:(...) and depression symptom severity(choose one: none, moderete, severe)\n",
    "'''\n",
    "\n",
    "def generation_pipeline(convo, top_k):\n",
    "    convo = convo\n",
    "    top_k = top_k\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abffb8",
   "metadata": {},
   "source": [
    "## Clean output\n",
    "\n",
    "given RAG output find the predicted label: (none/moderately depressed/severely depressed)\n",
    "\n",
    "### Input: RAG model's response Output: predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b364eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d686440c",
   "metadata": {},
   "source": [
    "## Run the RAG model\n",
    "\n",
    "given the Diac-Woz convo feed it through the retrival pipeline and pass it to the generation pipeline to retrieve the prompt for the RAG\n",
    "\n",
    "rags_output = run the model with the prompt and save whole output\n",
    "\n",
    "predicted label = run clean prompt to find classification label\n",
    "\n",
    "### input: diac-woz convo Output: RAG's output, predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494df0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3a8e589",
   "metadata": {},
   "source": [
    "## build dictionary\n",
    "\n",
    "(this will handle our txt and csv files to get the convos and their labels)\n",
    "\n",
    "for each convo in the diac-woz set feed it to the run the RAG function and build dictionary with (patient number): true label, predicted label, rags_output \n",
    "\n",
    "### Input: Diac woz full dataset (patient number, true label) Output: Clincal RAG prediction dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1c9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b92cfe0",
   "metadata": {},
   "source": [
    "## Test RAGS accuracy\n",
    "\n",
    " take all of the true label, predicted label pairs and calculate how many were correct\n",
    "\n",
    "### Input: RAG dictionary Output: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9a01c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
