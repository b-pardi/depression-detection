{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrade Embeddings to Larger Dimensions\n",
    "\n",
    "This notebook re-embeds your clinical chunks and DAIC-WOZ conversations with larger, better embedding models.\n",
    "\n",
    "**Recommended Models:**\n",
    "- `Alibaba-NLP/gte-large-en-v1.5` (1024d) - Best quality ‚≠ê\n",
    "- `nomic-ai/nomic-embed-text-v1.5` (768d) - Great for long texts\n",
    "- `BAAI/bge-large-en-v1.5` (1024d) - Excellent general purpose\n",
    "\n",
    "**Expected Time:** ~5-10 minutes with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Input: data/RAG\n",
      "  Output: data/RAG_1024d\n",
      "  Model: Alibaba-NLP/gte-large-en-v1.5\n",
      "  Batch sizes: chunks=32, convos=16\n"
     ]
    }
   ],
   "source": [
    "# Configuration - CHANGE THESE AS NEEDED\n",
    "INPUT_DIR = 'data/RAG'  # Your current data directory\n",
    "OUTPUT_DIR = 'data/RAG_1024d'  # Where to save upgraded embeddings\n",
    "\n",
    "# Choose your embedding model\n",
    "EMBEDDING_MODEL = 'Alibaba-NLP/gte-large-en-v1.5'  # 1024d - Best quality\n",
    "# EMBEDDING_MODEL = 'nomic-ai/nomic-embed-text-v1.5'  # 768d - Good for long texts\n",
    "# EMBEDDING_MODEL = 'BAAI/bge-large-en-v1.5'  # 1024d - Excellent general\n",
    "\n",
    "# Batch sizes (adjust based on GPU memory)\n",
    "BATCH_SIZE_CHUNKS = 32  # For short clinical chunks\n",
    "BATCH_SIZE_CONVOS = 16  # For long conversations\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Input: {INPUT_DIR}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Model: {EMBEDDING_MODEL}\")\n",
    "print(f\"  Batch sizes: chunks={BATCH_SIZE_CHUNKS}, convos={BATCH_SIZE_CONVOS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU Available: NVIDIA GeForce RTX 4070 SUPER\n",
      "   GPU Memory: 12.88 GB\n",
      "   Allocated: 0.00 GB\n",
      "   Available: 12.88 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    print(f\"   Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"   Available: {torch.cuda.get_device_properties(0).total_memory / 1e9 - reserved:.2f} GB\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, using CPU (this will be slow)\")\n",
    "    USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output directory ready: data/RAG_1024d\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"‚úÖ Output directory ready: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Alibaba-NLP/gte-large-en-v1.5...\n",
      "This may take a minute the first time (downloading model)\n",
      "\n",
      "‚úÖ Model loaded successfully\n",
      "   Device: cuda\n",
      "   Embedding dimension: 1024\n",
      "   Max sequence length: 8192\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "print(f\"Loading model: {EMBEDDING_MODEL}...\")\n",
    "print(\"This may take a minute the first time (downloading model)\")\n",
    "\n",
    "device = 'cuda' if USE_GPU else 'cpu'\n",
    "\n",
    "# Add trust_remote_code=True for Alibaba models\n",
    "embed_model = SentenceTransformer(\n",
    "    EMBEDDING_MODEL, \n",
    "    device=device,\n",
    "    trust_remote_code=True  # Required for Alibaba-NLP models\n",
    ")\n",
    "\n",
    "# Get embedding dimension\n",
    "EMBEDDING_DIM = embed_model.get_sentence_embedding_dimension()\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded successfully\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Embedding dimension: {EMBEDDING_DIM}\")\n",
    "print(f\"   Max sequence length: {embed_model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chunks from: data/RAG\\chunks.pkl\n",
      "‚úÖ Loaded 704 clinical chunks\n",
      "   First chunk preview (200 chars): Depressive disorders\n",
      "include disruptive mood dysregulation\n",
      "disorder, major depressive disorder (including major depressive episode),\n",
      "persistent depressive disorder, premenstrual dysphoric disorder,\n",
      "su...\n"
     ]
    }
   ],
   "source": [
    "# Load clinical chunks\n",
    "chunks_path = os.path.join(INPUT_DIR, 'chunks.pkl')\n",
    "print(f\"Loading chunks from: {chunks_path}\")\n",
    "\n",
    "with open(chunks_path, 'rb') as f:\n",
    "    chunks = pickle.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(chunks)} clinical chunks\")\n",
    "print(f\"   First chunk preview (200 chars): {chunks[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DAIC-WOZ data from: data/RAG\\diac_woz_data.pkl\n",
      "‚úÖ Loaded 189 patient conversations\n",
      "   Old embedding shape: (189, 384)\n",
      "   Available keys: ['patient_ids', 'conversations', 'embeddings', 'mdd_binary', 'phq8_scores']\n"
     ]
    }
   ],
   "source": [
    "# Load DAIC-WOZ data\n",
    "daic_path = os.path.join(INPUT_DIR, 'diac_woz_data.pkl')\n",
    "print(f\"Loading DAIC-WOZ data from: {daic_path}\")\n",
    "\n",
    "with open(daic_path, 'rb') as f:\n",
    "    daic_woz_data = pickle.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(daic_woz_data['patient_ids'])} patient conversations\")\n",
    "print(f\"   Old embedding shape: {daic_woz_data['embeddings'].shape}\")\n",
    "print(f\"   Available keys: {list(daic_woz_data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded mandatory context files\n",
      "   PHQ-8: 1517 characters\n",
      "   DSM-5: 15750 characters\n"
     ]
    }
   ],
   "source": [
    "# Load mandatory context files\n",
    "phq8_path = os.path.join(INPUT_DIR, 'phq8.txt')\n",
    "dsm5_path = os.path.join(INPUT_DIR, 'mandatory_context_DSM5_MMD.txt')\n",
    "\n",
    "with open(phq8_path, 'r', encoding='utf-8') as f:\n",
    "    phq8 = f.read()\n",
    "\n",
    "with open(dsm5_path, 'r', encoding='utf-8') as f:\n",
    "    dsm5 = f.read()\n",
    "\n",
    "print(f\"‚úÖ Loaded mandatory context files\")\n",
    "print(f\"   PHQ-8: {len(phq8)} characters\")\n",
    "print(f\"   DSM-5: {len(dsm5)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Re-embed Clinical Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Embedding 704 clinical chunks with Alibaba-NLP/gte-large-en-v1.5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d035a76c60c74bc59963680e74448130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Chunks embedded successfully\n",
      "   Shape: (704, 1024)\n",
      "   Dimension: 1024d\n",
      "   Upgrade: 384d ‚Üí 1024d\n"
     ]
    }
   ],
   "source": [
    "# Embed clinical chunks\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Embedding {len(chunks)} clinical chunks with {EMBEDDING_MODEL}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "chunk_embeddings = embed_model.encode(\n",
    "    chunks,\n",
    "    batch_size=BATCH_SIZE_CHUNKS,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,  # Important for cosine similarity\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Chunks embedded successfully\")\n",
    "print(f\"   Shape: {chunk_embeddings.shape}\")\n",
    "print(f\"   Dimension: {chunk_embeddings.shape[1]}d\")\n",
    "print(f\"   Upgrade: 384d ‚Üí {chunk_embeddings.shape[1]}d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating FAISS index...\n",
      "‚úÖ FAISS index created\n",
      "   Total vectors: 704\n",
      "   Dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index for clinical chunks\n",
    "print(f\"\\nCreating FAISS index...\")\n",
    "\n",
    "dimension = chunk_embeddings.shape[1]\n",
    "\n",
    "# Use IndexFlatIP for inner product (cosine similarity with normalized vectors)\n",
    "chunk_index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Add embeddings\n",
    "chunk_index.add(chunk_embeddings.astype('float32'))\n",
    "\n",
    "print(f\"‚úÖ FAISS index created\")\n",
    "print(f\"   Total vectors: {chunk_index.ntotal}\")\n",
    "print(f\"   Dimension: {dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved clinical chunks and index:\n",
      "   Chunks: data/RAG_1024d\\chunks.pkl\n",
      "   Index: data/RAG_1024d\\depression_embeddings_1024d.index\n"
     ]
    }
   ],
   "source": [
    "# Save chunks and index\n",
    "output_chunks_path = os.path.join(OUTPUT_DIR, 'chunks.pkl')\n",
    "output_index_path = os.path.join(OUTPUT_DIR, f'depression_embeddings_{dimension}d.index')\n",
    "\n",
    "with open(output_chunks_path, 'wb') as f:\n",
    "    pickle.dump(chunks, f)\n",
    "\n",
    "faiss.write_index(chunk_index, output_index_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved clinical chunks and index:\")\n",
    "print(f\"   Chunks: {output_chunks_path}\")\n",
    "print(f\"   Index: {output_index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXTRACTING PATIENT-ONLY RESPONSES\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting patient responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 189/189 [00:00<00:00, 16416.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction complete!\n",
      "   Total conversations: 189\n",
      "   Average full conversation: 13102 characters\n",
      "   Average patient-only: 7292 characters\n",
      "   Average reduction: 44.3%\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE: Patient 0\n",
      "================================================================================\n",
      "\n",
      "Full conversation (first 500 chars):\n",
      "speaker\tvalue\n",
      "Ellie\thi i'm ellie thanks for coming in today\n",
      "Ellie\ti was created to talk to people in a safe and secure environment\n",
      "Ellie\tthink of me as a friend i don't judge i can't i'm a computer\n",
      "Ellie\ti'm here to learn about people and would love to learn about you\n",
      "Ellie\ti'll ask a few questions to get us started and please feel free to tell me anything your answers are totally confidential\n",
      "Ellie\thow are you doing today\n",
      "Participant\tgood\n",
      "Ellie\tthat's good\n",
      "Ellie\twhere are you from originally\n",
      "Pa\n",
      "\n",
      "Patient-only (first 500 chars):\n",
      "good atlanta georgia um my parents are from here um i love it i like the weather i like the opportunities um yes um it took a minute somewhat easy congestion that's it um i took up business and administration uh yeah i am here and there i'm on a break right now but i plan on going back in the uh next semester uh probably to open up my own business no um no specific reason i just don't travel a lot i'm pretty local once a year can you be a little bit more specific no answer i like reading books i\n",
      "\n",
      "‚úÖ Statistics:\n",
      "   Average patient words per conversation: 1471\n",
      "   Shortest patient response: 852 chars\n",
      "   Longest patient response: 22745 chars\n",
      "\n",
      "‚úÖ Added to daic_woz_data:\n",
      "   'full_conversations' - original with Ellie + Participant\n",
      "   'patient_only_conversations' - patient responses only\n",
      "\n",
      "üöÄ Ready to embed patient-only conversations (will be much faster!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract patient-only responses for better retrieval\n",
    "\n",
    "def extract_patient_responses(conversation):\n",
    "    \"\"\"\n",
    "    Extract only patient/participant responses from DAIC-WOZ conversation\n",
    "    Format: tab-separated with \"speaker\\\\tvalue\"\n",
    "    \n",
    "    Args:\n",
    "        conversation: str - Full conversation with tab-separated format\n",
    "    \n",
    "    Returns:\n",
    "        str - Patient responses only, space-separated\n",
    "    \"\"\"\n",
    "    lines = conversation.split('\\n')\n",
    "    patient_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        # Split by tab\n",
    "        parts = line.split('\\t')\n",
    "        \n",
    "        # Need at least 2 parts (speaker and value)\n",
    "        if len(parts) >= 2:\n",
    "            speaker = parts[0].strip().lower()\n",
    "            value = parts[1].strip()\n",
    "            \n",
    "            # Check if speaker is participant\n",
    "            if speaker == 'participant' and value:\n",
    "                patient_lines.append(value)\n",
    "    \n",
    "    return ' '.join(patient_lines)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXTRACTING PATIENT-ONLY RESPONSES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract patient-only from all conversations\n",
    "patient_only_conversations = []\n",
    "\n",
    "for conv in tqdm(daic_woz_data['conversations'], desc=\"Extracting patient responses\"):\n",
    "    patient_only = extract_patient_responses(conv)\n",
    "    patient_only_conversations.append(patient_only)\n",
    "\n",
    "# Calculate statistics\n",
    "full_lengths = [len(conv) for conv in daic_woz_data['conversations']]\n",
    "patient_lengths = [len(patient) for patient in patient_only_conversations]\n",
    "\n",
    "avg_full = np.mean(full_lengths)\n",
    "avg_patient = np.mean(patient_lengths)\n",
    "reduction = (1 - avg_patient / avg_full) * 100\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction complete!\")\n",
    "print(f\"   Total conversations: {len(patient_only_conversations)}\")\n",
    "print(f\"   Average full conversation: {avg_full:.0f} characters\")\n",
    "print(f\"   Average patient-only: {avg_patient:.0f} characters\")\n",
    "print(f\"   Average reduction: {reduction:.1f}%\")\n",
    "\n",
    "# Show example\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXAMPLE: Patient 0\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nFull conversation (first 500 chars):\")\n",
    "print(daic_woz_data['conversations'][0][:500])\n",
    "print(f\"\\nPatient-only (first 500 chars):\")\n",
    "print(patient_only_conversations[0][:500])\n",
    "\n",
    "# Count how many patient responses per conversation\n",
    "response_counts = [text.split() for text in patient_only_conversations]\n",
    "avg_words = np.mean([len(words) for words in response_counts])\n",
    "print(f\"\\n‚úÖ Statistics:\")\n",
    "print(f\"   Average patient words per conversation: {avg_words:.0f}\")\n",
    "print(f\"   Shortest patient response: {min(patient_lengths)} chars\")\n",
    "print(f\"   Longest patient response: {max(patient_lengths)} chars\")\n",
    "\n",
    "# Store both versions\n",
    "daic_woz_data['full_conversations'] = daic_woz_data['conversations'].copy()\n",
    "daic_woz_data['patient_only_conversations'] = patient_only_conversations\n",
    "\n",
    "print(f\"\\n‚úÖ Added to daic_woz_data:\")\n",
    "print(f\"   'full_conversations' - original with Ellie + Participant\")\n",
    "print(f\"   'patient_only_conversations' - patient responses only\")\n",
    "print(f\"\\nüöÄ Ready to embed patient-only conversations (will be much faster!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Re-embed DAIC-WOZ Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Embedding 189 patient-only conversations\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eba7006d50c4418b836e82d60d98fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Conversations embedded successfully\n",
      "   Old shape: (189, 384)\n",
      "   New shape: (189, 1024)\n",
      "   Upgrade: 384d ‚Üí 1024d\n",
      "   üöÄ Using patient-only text for better retrieval!\n"
     ]
    }
   ],
   "source": [
    "# Embed PATIENT-ONLY conversations (faster and better retrieval!)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Embedding {len(patient_only_conversations)} patient-only conversations\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "conversation_embeddings = embed_model.encode(\n",
    "    patient_only_conversations,  # ‚úÖ Use patient-only\n",
    "    batch_size=BATCH_SIZE_CONVOS,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Conversations embedded successfully\")\n",
    "print(f\"   Old shape: {daic_woz_data['embeddings'].shape}\")\n",
    "print(f\"   New shape: {conversation_embeddings.shape}\")\n",
    "print(f\"   Upgrade: {daic_woz_data['embeddings'].shape[1]}d ‚Üí {conversation_embeddings.shape[1]}d\")\n",
    "print(f\"   üöÄ Using patient-only text for better retrieval!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated DAIC-WOZ data dictionary\n",
      "   New keys added: embedding_model, embedding_dimension, upgrade_date\n"
     ]
    }
   ],
   "source": [
    "# Update DAIC-WOZ data with new embeddings\n",
    "daic_woz_data['embeddings'] = conversation_embeddings\n",
    "daic_woz_data['embedding_model'] = EMBEDDING_MODEL\n",
    "daic_woz_data['embedding_dimension'] = dimension\n",
    "daic_woz_data['upgrade_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"‚úÖ Updated DAIC-WOZ data dictionary\")\n",
    "print(f\"   New keys added: embedding_model, embedding_dimension, upgrade_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved DAIC-WOZ data:\n",
      "   Path: data/RAG_1024d\\diac_woz_data_1024d.pkl\n",
      "   Embedding shape: (189, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Save updated DAIC-WOZ data\n",
    "output_daic_path = os.path.join(OUTPUT_DIR, f'diac_woz_data_{dimension}d.pkl')\n",
    "\n",
    "with open(output_daic_path, 'wb') as f:\n",
    "    pickle.dump(daic_woz_data, f)\n",
    "\n",
    "print(f\"‚úÖ Saved DAIC-WOZ data:\")\n",
    "print(f\"   Path: {output_daic_path}\")\n",
    "print(f\"   Embedding shape: {conversation_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Copy Mandatory Context Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying mandatory context files...\n",
      "  ‚úÖ Copied: phq8.txt\n",
      "  ‚úÖ Copied: mandatory_context_DSM5_MMD.txt\n"
     ]
    }
   ],
   "source": [
    "# Copy mandatory context files to new directory\n",
    "files_to_copy = ['phq8.txt', 'mandatory_context_DSM5_MMD.txt']\n",
    "\n",
    "print(\"Copying mandatory context files...\")\n",
    "\n",
    "for filename in files_to_copy:\n",
    "    src = os.path.join(INPUT_DIR, filename)\n",
    "    dst = os.path.join(OUTPUT_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "        print(f\"  ‚úÖ Copied: {filename}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Not found: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify Embeddings (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing retrieval with upgraded embeddings...\n",
      "================================================================================\n",
      "\n",
      "Test query: Patient 308\n",
      "True MDD: 1\n",
      "PHQ-8 Score: 22\n",
      "\n",
      "Top-5 retrieved chunks:\n",
      "\n",
      "Rank 1 | Similarity: 0.5679 | Chunk Index: 485\n",
      "with intense and persistent yearning and longing for the Latinos appear less likely to receive treatment for mood\n",
      "deceased person, and complicated by guilty or angry ru- disorders (663‚Äì665).\n",
      "minations...\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 2 | Similarity: 0.5591 | Chunk Index: 489\n",
      "tion that depression in the context of bereavement differs more likely to prefer counseling than whites, whereas Af-\n",
      "from other major depressive episodes, and data indicate rican Americans varied acro...\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 3 | Similarity: 0.5487 | Chunk Index: 540\n",
      "Hispanic, or black decreased risk (655). (about one-fifth of the total) received adequate treatment\n",
      "The impact of major depressive disorders on individu- (976). These findings highlight the need for c...\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 4 | Similarity: 0.5465 | Chunk Index: 302\n",
      "This specifier does not apply to those situations in which\n",
      "the pattern is better explained by seasonally linkedpsychosocial stressors (e.g., seasonal unemployment or\n",
      "school schedule). Major depressive...\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 5 | Similarity: 0.5391 | Chunk Index: 79\n",
      "determinants of mental health, such as low income, limited formal\n",
      "education, racism, and other forms of discrimination, are associated with\n",
      "higher risk of major depressive disorder. Stressful life eve...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Retrieval test complete!\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval with new embeddings\n",
    "print(\"\\nTesting retrieval with upgraded embeddings...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Pick a test conversation (e.g., patient 0)\n",
    "test_idx = 8\n",
    "test_embedding = conversation_embeddings[test_idx].reshape(1, -1).astype('float32')\n",
    "faiss.normalize_L2(test_embedding)\n",
    "\n",
    "# Search for top-5 similar chunks\n",
    "k = 5\n",
    "distances, indices = chunk_index.search(test_embedding, k)\n",
    "\n",
    "print(f\"\\nTest query: Patient {daic_woz_data['patient_ids'][test_idx]}\")\n",
    "print(f\"True MDD: {daic_woz_data['mdd_binary'][test_idx]}\")\n",
    "print(f\"PHQ-8 Score: {daic_woz_data['phq8_scores'][test_idx]}\")\n",
    "print(f\"\\nTop-{k} retrieved chunks:\\n\")\n",
    "\n",
    "for i, (idx, score) in enumerate(zip(indices[0], distances[0])):\n",
    "    print(f\"Rank {i+1} | Similarity: {score:.4f} | Chunk Index: {idx}\")\n",
    "    print(f\"{chunks[idx][:200]}...\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ Retrieval test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created README: data/RAG_1024d\\README.md\n"
     ]
    }
   ],
   "source": [
    "# Create README with information about the upgrade\n",
    "readme_content = f\"\"\"# Upgraded Embeddings\n",
    "\n",
    "## Model Information\n",
    "- **Model**: {EMBEDDING_MODEL}\n",
    "- **Embedding dimension**: {dimension}\n",
    "- **Original dimension**: 384\n",
    "- **Date created**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- **Device used**: {device.upper()}\n",
    "\n",
    "## Files\n",
    "- `chunks.pkl` - {len(chunks)} clinical text chunks\n",
    "- `depression_embeddings_{dimension}d.index` - FAISS index for chunks\n",
    "- `diac_woz_data_{dimension}d.pkl` - {len(daic_woz_data['patient_ids'])} patient conversations with embeddings\n",
    "- `phq8.txt` - PHQ-8 questionnaire (mandatory context)\n",
    "- `mandatory_context_DSM5_MMD.txt` - DSM-5 criteria (mandatory context)\n",
    "\n",
    "## Usage\n",
    "Update your notebook to load from this directory:\n",
    "\n",
    "```python\n",
    "# Load chunks and index\n",
    "with open('{OUTPUT_DIR}/chunks.pkl', 'rb') as f:\n",
    "    chunks = pickle.load(f)\n",
    "\n",
    "index = faiss.read_index('{OUTPUT_DIR}/depression_embeddings_{dimension}d.index')\n",
    "\n",
    "# Load DAIC-WOZ data\n",
    "with open('{OUTPUT_DIR}/diac_woz_data_{dimension}d.pkl', 'rb') as f:\n",
    "    daic_woz_data = pickle.load(f)\n",
    "\n",
    "# Load mandatory context\n",
    "with open('{OUTPUT_DIR}/phq8.txt', 'r', encoding='utf-8') as f:\n",
    "    phq8 = f.read()\n",
    "    \n",
    "with open('{OUTPUT_DIR}/mandatory_context_DSM5_MMD.txt', 'r', encoding='utf-8') as f:\n",
    "    dsm5 = f.read()\n",
    "```\n",
    "\n",
    "## Expected Performance Improvements\n",
    "With {dimension}d embeddings vs 384d:\n",
    "- Better semantic understanding of clinical concepts\n",
    "- Improved retrieval accuracy (+5-10% typical)\n",
    "- More nuanced similarity scores\n",
    "- Better handling of long conversation contexts\n",
    "\"\"\"\n",
    "\n",
    "readme_path = os.path.join(OUTPUT_DIR, 'README.md')\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"‚úÖ Created README: {readme_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéâ EMBEDDING UPGRADE COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Upgrade Summary:\n",
      "  Old embeddings: 384 dimensions\n",
      "  New embeddings: 1024 dimensions\n",
      "  Model used: Alibaba-NLP/gte-large-en-v1.5\n",
      "  Device: CUDA\n",
      "\n",
      "Files saved to: data/RAG_1024d\n",
      "  ‚úÖ chunks.pkl\n",
      "  ‚úÖ depression_embeddings_1024d.index\n",
      "  ‚úÖ diac_woz_data_1024d.pkl\n",
      "  ‚úÖ phq8.txt\n",
      "  ‚úÖ mandatory_context_DSM5_MMD.txt\n",
      "  ‚úÖ README.md\n",
      "\n",
      "Next steps:\n",
      "  1. Run 'run_large_model_rag.ipynb' with this new data directory\n",
      "  2. Use a larger model (e.g., Llama 70B) for better inference\n",
      "  3. Compare results with old 384d embeddings\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ EMBEDDING UPGRADE COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nUpgrade Summary:\")\n",
    "print(f\"  Old embeddings: 384 dimensions\")\n",
    "print(f\"  New embeddings: {dimension} dimensions\")\n",
    "print(f\"  Model used: {EMBEDDING_MODEL}\")\n",
    "print(f\"  Device: {device.upper()}\")\n",
    "print(f\"\\nFiles saved to: {OUTPUT_DIR}\")\n",
    "print(f\"  ‚úÖ chunks.pkl\")\n",
    "print(f\"  ‚úÖ depression_embeddings_{dimension}d.index\")\n",
    "print(f\"  ‚úÖ diac_woz_data_{dimension}d.pkl\")\n",
    "print(f\"  ‚úÖ phq8.txt\")\n",
    "print(f\"  ‚úÖ mandatory_context_DSM5_MMD.txt\")\n",
    "print(f\"  ‚úÖ README.md\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Run 'run_large_model_rag.ipynb' with this new data directory\")\n",
    "print(f\"  2. Use a larger model (e.g., Llama 70B) for better inference\")\n",
    "print(f\"  3. Compare results with old 384d embeddings\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
